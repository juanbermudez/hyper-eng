# Hyper Planning Workflow
#
# Full planning workflow with 3 HITL gates:
#   Gate 1: Pre-research clarification
#   Gate 2: Post-research direction approval
#   Gate 3: Spec approval before task creation
#
# Usage: hypercraft run hyper-plan.prose feature="Add user authentication"
#
# ARTIFACT PATTERN:
# - Hypercraft bindings (.prose/runs/) = execution state, pointers to artifacts
# - Project artifacts (projects/) = actual deliverables via CLI
#
# PATH RESOLUTION:
# $HYPER_WORKSPACE_ROOT = ~/.hyper/accounts/{userId}/hyper/workspaces/{workspaceId}/
#
# STATUS FLOW:
# Project: planned → todo → in-progress → qa → completed
# Task: todo → in-progress → qa → complete

input feature: "Feature description to plan"
input depth: "Research depth: comprehensive (default) or deep"

# ============================================================================
# Agent Definitions
# ============================================================================

agent hyper-captain:
  model: opus
  persist: true
  skills:
    - hyper-craft              # Core knowledge (always loaded)
    - hyper-planning           # Planning-specific workflows
  prompt: """You are the Hyper Captain - the orchestrator for planning workflows.

Your role:
1. Coordinate research sub-agents
2. Synthesize findings into specifications
3. Present plans for human approval at gates
4. Create tasks from approved specs

Key principles:
- Specs matter more than code
- Always wait for human approval at HITL gates
- Use hypercraft CLI for all artifact creation (see hyper-craft skill)
- Follow output contract format (see hyper-craft skill)
- At approval gates: READ the artifact content and DISPLAY it to the user

ARTIFACT PATTERN (from hyper-craft):
- Write ARTIFACTS to $HYPER_WORKSPACE_ROOT/projects/ using the CLI
- Write BINDINGS as pointers/summaries to track execution state"""

agent repo-analyst:
  model: sonnet
  skills:
    - hyper-craft              # Core knowledge
    - code-search              # Codebase analysis
  prompt: """You analyze repository structure, patterns, and conventions.
Return findings using the output contract format from hyper-craft."""

agent best-practices:
  model: sonnet
  skills:
    - hyper-craft              # Core knowledge
    - doc-lookup               # Web/documentation search
  prompt: """You research external best practices and industry standards.
Return findings using the output contract format from hyper-craft."""

agent framework-docs:
  model: sonnet
  skills:
    - hyper-craft              # Core knowledge
    - doc-lookup               # Documentation retrieval
  prompt: """You fetch and analyze framework/library documentation.
Return findings using the output contract format from hyper-craft."""

agent git-analyzer:
  model: sonnet
  skills:
    - hyper-craft              # Core knowledge
    - code-search              # Git history analysis
  prompt: """You analyze git history to understand code evolution.
Return findings using the output contract format from hyper-craft."""

# ============================================================================
# Phase 1: Initialize
# ============================================================================

let init = session "Initialize planning workflow"
  prompt: """Initialize the planning workflow.

1. Resolve workspace:
```bash
WORKSPACE_ROOT=$(${CLAUDE_PLUGIN_ROOT}/binaries/hypercraft config get globalPath)
export HYPER_WORKSPACE_ROOT="$WORKSPACE_ROOT"
echo "WORKSPACE_ROOT=$WORKSPACE_ROOT"
```

2. Generate run ID and project slug:
```bash
RUN_ID="plan-$(date +%Y%m%d-%H%M%S)-$(uuidgen | cut -c1-8)"
PROJECT_SLUG=$(echo "{feature}" | tr '[:upper:]' '[:lower:]' | tr ' ' '-' | sed 's/[^a-z0-9-]//g')
echo "RUN_ID=$RUN_ID"
echo "PROJECT_SLUG=$PROJECT_SLUG"
```

3. Create Hypercraft state directory:
```bash
mkdir -p "$HYPER_WORKSPACE_ROOT/.prose/runs/$RUN_ID/bindings"
mkdir -p "$HYPER_WORKSPACE_ROOT/.prose/agents/hyper-captain"
```

4. Ensure project exists (create if missing):
```bash
${CLAUDE_PLUGIN_ROOT}/binaries/hypercraft project get "$PROJECT_SLUG" --json >/dev/null 2>&1 || \
  ${CLAUDE_PLUGIN_ROOT}/binaries/hypercraft project create \
    --slug "$PROJECT_SLUG" \
    --title "{feature}" \
    --priority "high" \
    --status "planned" \
    --json
```

5. Create project directory structure:
```bash
mkdir -p "$HYPER_WORKSPACE_ROOT/projects/$PROJECT_SLUG/resources"
mkdir -p "$HYPER_WORKSPACE_ROOT/projects/$PROJECT_SLUG/tasks"
```

Report: WORKSPACE_ROOT, RUN_ID, PROJECT_SLUG

Artifact locations that will be created:
- Project spec: $HYPER_WORKSPACE_ROOT/projects/$PROJECT_SLUG/_project.mdx
- Research: $HYPER_WORKSPACE_ROOT/projects/$PROJECT_SLUG/resources/research-summary.md
- Tasks: $HYPER_WORKSPACE_ROOT/projects/$PROJECT_SLUG/tasks/task-NNN.mdx"""

# ============================================================================
# Phase 2: Pre-Research Clarification (HITL Gate 1)
# ============================================================================

let clarification = session: hyper-captain
  prompt: """HITL GATE 1: Pre-Research Clarification

Before spawning research agents, confirm understanding with the user.

**Feature Request**: {feature}

Use AskUserQuestion to clarify:

1. **Scope Confirmation**: Present your understanding of what "{feature}" means
   - What problem does this solve?
   - Who is the user/beneficiary?
   - What are the expected inputs/outputs?

2. **Boundary Questions**: Ask about scope limits
   - What is explicitly OUT of scope?
   - Are there related features we should NOT touch?
   - Any specific constraints (tech stack, patterns to follow)?

3. **Success Criteria**: What does "done" look like?
   - How will we verify this works?
   - Are there acceptance criteria already defined?

Wait for user response before proceeding to research.

After clarification, summarize:
- Confirmed understanding
- Scope boundaries
- Key constraints
- Success criteria"""
  context: { feature, init }

# ============================================================================
# Phase 3: Research
# ============================================================================

if **clarification complete**:
  # Query existing learnings before spawning research agents
  let prior_learnings = session "Query existing learnings"
    prompt: """Search for relevant learnings from previous projects.

```bash
# Search for learnings related to this feature
FEATURE_KEYWORDS=$(echo "{feature}" | tr '[:upper:]' '[:lower:]' | tr ' ' '\n' | grep -v "^$")
for keyword in $FEATURE_KEYWORDS; do
  grep -r -l -i "$keyword" $HYPER_WORKSPACE_ROOT/projects/*/resources/learnings.md 2>/dev/null || true
done | sort -u
```

If learnings found, read and summarize relevant entries.
If none found, report: "No prior learnings found for this feature area."

This helps avoid repeating past mistakes during research and implementation."""
    context: { feature, clarification, init }

  # Spawn skill-based research agents in parallel
  parallel:
    repo_findings = session: repo-analyst
      prompt: """Analyze repository structure for: {feature}

Search for:
- Existing patterns and conventions
- Similar implementations
- Related code areas

Clarified scope: {clarification}

Write findings to:
$HYPER_WORKSPACE_ROOT/projects/{project_slug}/resources/codebase-analysis.md"""
      context: { feature, clarification, init }

    practices_findings = session: best-practices
      prompt: """Research best practices for: {feature}

Search for:
- Industry standards
- Security considerations
- Performance patterns

Clarified scope: {clarification}

Write findings to:
$HYPER_WORKSPACE_ROOT/projects/{project_slug}/resources/best-practices.md"""
      context: { feature, clarification, init }

    docs_findings = session: framework-docs
      prompt: """Fetch framework documentation for: {feature}

Look up:
- Relevant API documentation
- Official guides
- Migration notes if applicable

Clarified scope: {clarification}

Write findings to:
$HYPER_WORKSPACE_ROOT/projects/{project_slug}/resources/framework-docs.md"""
      context: { feature, clarification, init }

    history_findings = session: git-analyzer
      prompt: """Analyze git history related to: {feature}

Examine:
- Evolution of related code
- Previous attempts or related features
- Key contributors

Clarified scope: {clarification}

Write findings to:
$HYPER_WORKSPACE_ROOT/projects/{project_slug}/resources/git-history.md"""
      context: { feature, clarification, init }

  let research = session: hyper-captain
    prompt: """Synthesize research findings from parallel agents.

Read the research artifacts:
- projects/{project_slug}/resources/codebase-analysis.md
- projects/{project_slug}/resources/best-practices.md
- projects/{project_slug}/resources/framework-docs.md
- projects/{project_slug}/resources/git-history.md

Also incorporate any prior learnings: {prior_learnings}

Create a unified research summary that includes:
1. Codebase patterns and conventions
2. Best practices and industry standards
3. Framework documentation insights
4. Git history context
5. **Prior learnings to consider** (from compound engineering)

```bash
${CLAUDE_PLUGIN_ROOT}/binaries/hypercraft file write \\
  "projects/$PROJECT_SLUG/resources/research-summary.md" \\
  --body "[synthesized research content]"
```

The binding should contain:
- Summary of key findings
- Pointer to artifact: projects/{project_slug}/resources/research-summary.md
- Key insights for specification phase
- Prior learnings that apply to this feature"""
    context: { feature, clarification, init, repo_findings, practices_findings, docs_findings, history_findings, prior_learnings }

# ============================================================================
# Phase 4: Direction Gate (HITL Gate 2)
# ============================================================================

let direction = session: hyper-captain
  prompt: """HITL GATE 2: Post-Research Direction Approval

**IMPORTANT**: Read and display the actual research artifact to the user.

1. Read the research artifact:
```bash
${CLAUDE_PLUGIN_ROOT}/binaries/hypercraft file read \\
  "projects/$PROJECT_SLUG/resources/research-summary.md" \\
  --json
```

2. Present to user with AskUserQuestion:

## Direction Check

**Feature**: {feature}

### Research Findings
[Display the FULL content from the research artifact - do NOT summarize]

### Proposed Approach
Based on research, outline:
- High-level architecture/approach
- Key components to create/modify
- Integration points

### Key Decisions Needed
1. [Decision point 1 - present options]
2. [Decision point 2 - present options]

### Potential Risks
- [Risk 1 and mitigation]
- [Risk 2 and mitigation]

---

**GATE: Direction Approval Required**

Ask user:
- Approve this direction?
- Any adjustments needed?
- Additional constraints to consider?

Wait for explicit approval before proceeding."""
  context: { feature, research, clarification, init }

# ============================================================================
# Phase 5: Detailed Specification
# ============================================================================

if **direction approved**:
  let spec = session: hyper-captain
    prompt: """Create detailed specification and write to artifact.

1. Write FULL specification to _project.mdx:
```bash
${CLAUDE_PLUGIN_ROOT}/binaries/hypercraft file write \\
  "projects/$PROJECT_SLUG/_project.mdx" \\
  --body "[full specification content]"
```

The specification MUST include:
- ## Overview - Problem statement and solution
- ## Goals - Numbered list of objectives
- ## Technical Approach - Architecture, components, patterns
- ## Implementation Phases - Numbered phases for task breakdown
- ## Acceptance Criteria - Testable success conditions
- ## Out of Scope - Explicit exclusions

The binding for this session should contain:
- Summary of spec created
- Pointer to artifact: projects/{project_slug}/_project.mdx
- List of implementation phases for task creation"""
    context: { feature, research, direction, clarification, init }

# ============================================================================
# Phase 6: Spec Approval Gate (HITL Gate 3)
# ============================================================================

let spec_approval = session: hyper-captain
  prompt: """HITL GATE 3: Specification Approval

**IMPORTANT**: Read and display the actual spec artifact to the user.

1. Read the project spec:
```bash
${CLAUDE_PLUGIN_ROOT}/binaries/hypercraft file read \\
  "projects/$PROJECT_SLUG/_project.mdx" \\
  --json
```

2. Present FULL specification to user:

## Specification Review

**Project**: {feature}
**Location**: $HYPER_WORKSPACE_ROOT/projects/{project_slug}/_project.mdx

### Full Specification
[Display the ENTIRE content from _project.mdx - do NOT summarize]

---

**GATE: Specification Approval Required**

Ask user:
- Approve this specification?
- Any sections need revision?
- Ready to create tasks?

Wait for explicit approval before creating tasks."""
  context: { spec, init }

# ============================================================================
# Phase 7: Task Breakdown
# ============================================================================

if **spec approved**:
  let tasks = session: hyper-captain
    prompt: """Create tasks from approved specification.

1. Read the spec to extract implementation phases:
```bash
${CLAUDE_PLUGIN_ROOT}/binaries/hypercraft file read \\
  "projects/$PROJECT_SLUG/_project.mdx" \\
  --json
```

2. For EACH phase in the spec, create a task:
```bash
# Create task via CLI (generates ID automatically)
TASK_RESULT=$(${CLAUDE_PLUGIN_ROOT}/binaries/hypercraft task create \\
  --project "$PROJECT_SLUG" \\
  --title "Phase N: [Phase Title]" \\
  --priority "high" \\
  --json)

# Extract task ID from result
TASK_ID=$(echo "$TASK_RESULT" | jq -r '.id')
TASK_FILE=$(echo "$TASK_RESULT" | jq -r '.file')
```

3. Write FULL task content to each task file:
```bash
${CLAUDE_PLUGIN_ROOT}/binaries/hypercraft file write \\
  "$TASK_FILE" \\
  --body "[full task specification]"
```

Each task body MUST include:
- ## Objective - What this task accomplishes
- ## Implementation Steps - Numbered steps to complete
- ## Acceptance Criteria - How to verify completion
- ## Dependencies - Other tasks this depends on (if any)

4. Update project status to 'todo':
```bash
${CLAUDE_PLUGIN_ROOT}/binaries/hypercraft project update "$PROJECT_SLUG" --status "todo"
```

The binding for this session should contain:
- List of tasks created with IDs
- Pointer to each task file
- Summary of task breakdown"""
    context: { spec, init }

# ============================================================================
# Output Summary
# ============================================================================

output summary = session: hyper-captain
  prompt: """Generate planning summary.

Read the final project state:
```bash
${CLAUDE_PLUGIN_ROOT}/binaries/hypercraft project get "$PROJECT_SLUG" --json
${CLAUDE_PLUGIN_ROOT}/binaries/hypercraft task list --project "$PROJECT_SLUG" --json
```

## Planning Complete

**Project**: {feature}
**Slug**: {project_slug}
**Status**: todo

### Artifacts Created

| Artifact | Location |
|----------|----------|
| Project Spec | `$HYPER_WORKSPACE_ROOT/projects/{project_slug}/_project.mdx` |
| Research Summary | `$HYPER_WORKSPACE_ROOT/projects/{project_slug}/resources/research-summary.md` |
| Tasks | `$HYPER_WORKSPACE_ROOT/projects/{project_slug}/tasks/task-NNN.mdx` |

### Tasks Created
[List all tasks with IDs and titles from CLI output]

### Next Steps
1. Run `/hyper:implement {project_slug}` to start implementation
2. Or implement individual tasks: `/hyper:implement {project_slug}/{task_id}`

### Hypercraft State (for workflow resume)
`$HYPER_WORKSPACE_ROOT/.prose/runs/{run_id}/`
"""
  context: { feature, init, spec, tasks }

# ============================================================================
# Phase 8: Compound Engineering (Optional)
# ============================================================================

agent compounding-agent:
  model: sonnet
  skills:
    - hyper-craft              # Core knowledge
    - compound-engineering     # Trigger detection and learnings
  prompt: """You extract and document learnings from session events.

Your responsibilities:
1. Analyze triggers detected during the workflow
2. Extract meaningful insights (not trivial errors)
3. Format learnings using the compound-engineering skill structure
4. Write to the project's learnings file

Skip trivial issues. Focus on non-obvious solutions and patterns."""

# Check for compound engineering triggers at workflow end
let triggers = **detect_compound_triggers(session)**

if triggers.length > 0:
  session: compounding-agent
    prompt: """Review the planning workflow for compound engineering opportunities.

    **Triggers Detected**:
    {triggers}

    For each significant trigger, evaluate:
    1. Is this worth documenting? (non-obvious solution, repeated issue, etc.)
    2. What category does it fall into?
    3. What are the key learnings?

    If worth documenting, write to:
    `$HYPER_WORKSPACE_ROOT/projects/{project_slug}/resources/learnings.md`

    Use the learnings schema from compound-engineering skill:
    - Title: [Category]: [Descriptive Title]
    - Include: context, what happened, root cause, solution, future prevention
    - Add relevant tags for searchability

    If no triggers worth documenting, report: "No significant learnings to capture."
    """
    context: { triggers, feature, init }
